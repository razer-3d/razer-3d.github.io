<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RAZER: Robust Accelerated Zero-Shot 3D Open-Vocabulary Panoptic Reconstruction</title>
    <meta name="description"
        content="Official project page for RAZER: A zero-shot framework that seamlessly integrates GPU-accelerated geometric reconstruction with open-vocabulary vision-language models through online instance-level semantic embedding fusion.">

    <!-- Stylesheets -->
    <link rel="stylesheet" href="css/style.css">
    <link rel="stylesheet"
        href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;600;700&family=Source+Sans+Pro:wght@400;600&display=swap">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
</head>

<body>
    <!-- Navigation -->
    <div class="nav-container">
        <div class="container">
            <nav>
                <div class="left-logo">
                    <a href="https://crrl.poly.edu/" target="_blank" class="nav-icon-link crrl-logo" title="CRRL Website">
                        <img src="crrl.jpg" alt="CRRL Logo" class="nav-logo-img">
                    </a>
                </div>
                <div class="nav-center">
                    <a href="#" class="nav-logo">RAZER</a>
                    <div class="nav-links">
                        <a href="#abstract">Abstract</a>
                        <a href="#overview">Overview</a>
                        <a href="#method">Method</a>
                        <a href="#applications">Applications</a>
                        <a href="#citation">Citation</a>
                    </div>
                </div>
                <div class="right-logo">
                    <a href="https://engineering.nyu.edu/" target="_blank" class="nav-icon-link nyu-logo" title="NYU Tandon School of Engineering">
                        <img src="NYU.jpg" alt="NYU Logo" class="nav-logo-img">
                    </a>
                </div>
                <div class="hamburger">
                    <i class="fas fa-bars"></i>
                </div>
            </nav>
        </div>
    </div>

    <!-- Hero Section -->
    <section class="hero">
        <div class="container hero-content">
            <h1>RAZER: Robust Accelerated Zero-Shot 3D Open-Vocabulary Panoptic Reconstruction with Spatio-Temporal
                Aggregation</h1>

            <div class="authors">
                <div class="author">
                    <a href="#">Naman Patel</a>
                </div>
                <div class="author">
                    <a href="#">Prashanth Krishnamurthy</a>
                </div>
                <div class="author">
                    <a href="#">Farshad Khorrami</a>
                </div>
            </div>

            <p><a href="https://crrl.poly.edu/" target="_blank" class="crrl-link">Control/Robotics Research Laboratory (CRRL)</a>, Department of Electrical and Computer
                Engineering, NYU Tandon School of Engineering</p>

            <div class="paper-links">
                <a href="razer_open_vocab.pdf" class="button button-primary" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                <span class="button button-disabled">
                    <i class="fas fa-code-branch"></i> 
                    <span>Code (Coming Soon)</span>
                    <span class="tooltip">Code will be available upon publication</span>
                </span>
                <span class="button button-disabled">
                    <i class="fas fa-archive"></i>
                    <span>arXiv (Coming Soon)</span>
                    <span class="tooltip">Paper will be released on arXiv when available</span>
                </span>
            </div>
        </div>
    </section>

    <!-- Abstract Section -->
    <section class="section section-light" id="abstract">
        <div class="container">
            <h2>Abstract</h2>
            <div class="abstract">
                <p>
                    Mapping and understanding complex 3D environments is fundamental to how autonomous systems perceive
                    and interact with the physical world, requiring both precise geometric reconstruction and rich
                    semantic comprehension. While existing 3D semantic mapping systems excel at reconstructing and
                    identifying predefined object instances, they lack the flexibility to efficiently build semantic
                    maps with open-vocabulary during online operation. Although recent vision-language models have
                    enabled open-vocabulary object recognition in 2D images, they haven’t yet bridged the gap to 3D
                    spatial understanding. The critical challenge lies in developing a training-free unified system that
                    can simultaneously construct accurate 3D maps while maintaining semantic consistency and supporting
                    natural language interactions in real time. In this paper, we develop a zero-shot framework that
                    seamlessly integrates GPU-accelerated geometric reconstruction with open-vocabulary vision-language
                    models through online instance-level semantic embedding fusion, guided by hierarchical object
                    association with spatial indexing. Our training-free system achieves superior performance through
                    incremental processing and unified geometric-semantic updates, while robustly handling 2D
                    segmentation inconsistencies. The proposed general-purpose 3D scene understanding framework can be
                    used for various tasks including zero-shot 3D instance retrieval, segmentation, and object detection
                    to reason about previously unseen objects and interpret natural language queries.
                </p>
            </div>
        </div>
    </section>

    <!-- Teaser Video Section -->
    <section class="section section-dark" id="overview">
        <div class="container">
            <h2>System Overview</h2>

            <div class="video-container">
                <div class="embedded-video">
                    <iframe width="100%" height="500" 
                        src="https://www.youtube.com/embed/a0oEoFxLR4g" 
                        title="RAZER: Robust Accelerated Zero-Shot 3D Open-Vocabulary Panoptic Reconstruction" 
                        frameborder="0" 
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
                        allowfullscreen>
                    </iframe>
                </div>
                <div class="figure-caption">
                    <strong>Video:</strong> RAZER in action - demonstrating real-time 3D scene understanding
                    capabilities with open-vocabulary semantic mapping.
                </div>
            </div>

            <div class="figure">
                <img src="images/overview.png" alt="RAZER System Overview">
                <div class="figure-caption">
                    <strong>Figure 1:</strong> Pipeline overview of our proposed 3D scene understanding framework. Our
                    system processes posed RGB-D inputs through open-vocabulary segmentation for robust 3D instance
                    tracking. Spatio-temporal feature aggregation fuses and prunes tracks while updating a panoptic map
                    that enables online text-based 3D instance retrieval and segmentation tasks.
                </div>
            </div>
        </div>
    </section>

    <!-- Key Contributions Section -->
    <section class="section section-light">
        <div class="container">
            <h2>Key Contributions</h2>

            <div class="contributions">
                <div class="contribution fade-in">
                    <div class="contribution-icon">
                        <i class="fas fa-globe"></i>
                    </div>
                    <h3>Zero-Shot Understanding</h3>
                    <p>Integrates vision-language models with 3D reconstruction for open-vocabulary recognition 
                        of diverse object categories without requiring additional training.</p>
                </div>

                <div class="contribution fade-in">
                    <div class="contribution-icon">
                        <i class="fas fa-tachometer-alt"></i>
                    </div>
                    <h3>Real-Time Performance</h3>
                    <p>CUDA-accelerated processing at 103ms/frame (4× faster than comparable methods) with 
                        optimized algorithms for efficient mapping without global optimization.</p>
                </div>

                <div class="contribution fade-in">
                    <div class="contribution-icon">
                        <i class="fas fa-project-diagram"></i>
                    </div>
                    <h3>R-Tree Spatial Indexing</h3>
                    <p>Efficient O(log n) object association using spatial hierarchies with Hungarian matching 
                        for improved tracking through occlusions and viewpoint changes.</p>
                </div>

                <div class="contribution fade-in">
                    <div class="contribution-icon">
                        <i class="fas fa-layer-group"></i>
                    </div>
                    <h3>Spatio-Temporal Aggregation</h3>
                    <p>Instance-level semantic embedding fusion across frames, guided by hierarchical object 
                        association for consistent identity tracking in dynamic environments.</p>
                </div>
                
                <div class="contribution fade-in">
                    <div class="contribution-icon">
                        <i class="fas fa-database"></i>
                    </div>
                    <h3>Multi-Embedding Fusion</h3>
                    <p>Maintains up to three semantic embeddings per object with confidence-based pruning 
                        to handle ambiguous interpretations in complex, cluttered scenes.</p>
                </div>

                <div class="contribution fade-in">
                    <div class="contribution-icon">
                        <i class="fas fa-cubes"></i>
                    </div>
                    <h3>Unified Geometric-Semantic Mapping</h3>
                    <p>TSDF-based approach combining volumetric reconstruction with semantic embedding updates
                        to address 2D segmentation inconsistencies during 3D mapping.</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Method Section -->
    <section class="section section-dark" id="method">
        <div class="container">
            <h2>Method</h2>

            <div class="method-overview">
                <div class="figure">
                    <img src="images/system.png" alt="RAZER System Architecture">
                    <div class="figure-caption">
                        <strong>Figure 2:</strong> System-level architecture of RAZER with three main modules: (1)
                        Instance Tracking, (2) Aggregation Manager, and (3) Map Update. RGB-D inputs are processed
                        through open-vocabulary segmentation, maintaining a unified voxel-based representation.
                    </div>
                </div>
            </div>

            <div class="method-columns">
                <div class="method-column fade-in">
                    <div class="method-icon">
                        <i class="fas fa-cube"></i>
                    </div>
                    <h3>3D Object Detection & Tracking</h3>
                    <p>Open-vocabulary segmentation masks are back-projected to 3D and clustered with DBSCAN to handle occlusions.
                       Objects are tracked via R-tree spatial indexing and Hungarian bipartite matching, with incremental
                       OBB updates to refine geometric estimates as new observations arrive.</p>
                </div>

                <div class="method-column fade-in">
                    <div class="method-icon">
                        <i class="fas fa-network-wired"></i>
                    </div>
                    <h3>Semantic Embedding Management</h3>
                    <p>Features from each mask are pooled to form semantic embeddings in a continuous representation space.
                       Up to three embeddings per object are maintained with confidence scores, using a similarity-based 
                       fusion mechanism to handle ambiguous interpretations and resolve them over time.</p>
                </div>

                <div class="method-column fade-in">
                    <div class="method-icon">
                        <i class="fas fa-cubes"></i>
                    </div>
                    <h3>Volumetric Reconstruction</h3>
                    <p>A TSDF-based representation combines both geometric and semantic information at the voxel level.
                       Each voxel stores signed distance, color, instance labels, and a histogram of observations, updated
                       incrementally with GPU acceleration to maintain geometric-semantic consistency.</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Applications Section -->
    <section class="section section-light" id="applications">
        <div class="container">
            <h2>Applications</h2>

            <div class="method-columns">
                <div class="method-column fade-in">
                    <div class="method-icon">
                        <i class="fas fa-object-group"></i>
                    </div>
                    <h3>3D Instance Segmentation</h3>
                    <p>RAZER maintains instance-level bounding boxes and voxel-level labels, providing complete 3D
                        segmentation that updates in real-time as new viewpoints become available. This enables
                        applications like robotic manipulation that require precise object boundaries.</p>
                </div>

                <div class="method-column fade-in">
                    <div class="method-icon">
                        <i class="fas fa-th"></i>
                    </div>
                    <h3>3D Semantic Segmentation</h3>
                    <p>Our framework performs open-vocabulary 3D semantic segmentation with state-of-the-art
                        performance, nearly doubling the effectiveness of previous approaches while
                        preserving fine-grained details across diverse object categories.</p>
                </div>

                <div class="method-column fade-in">
                    <div class="method-icon">
                        <i class="fas fa-search"></i>
                    </div>
                    <h3>3D Instance Retrieval</h3>
                    <p>The open-vocabulary embeddings enable text-based object search in 3D environments. Natural
                        language queries are processed through the same vision-language model to retrieve semantically
                        similar objects without requiring specific class training.</p>
                </div>
            </div>
        </div>
    </section>


    <!-- Citation Section -->
    <section class="section section-light" id="citation">
        <div class="container">
            <h2>Citation</h2>

            <div class="citation">
                <button class="copy-button">
                    <i class="fas fa-copy"></i> Copy BibTeX
                    <span class="copy-btn-tooltip">Click to copy</span>
                </button>
                <pre>@article{patel2025razer,
  title={RAZER: Robust Accelerated Zero-Shot 3D Open-Vocabulary Panoptic Reconstruction with Spatio-Temporal Aggregation},
  author={Patel, Naman and Krishnamurthy, Prashanth and Khorrami, Farshad},
  journal={arXiv preprint},
  year={2025}
}</pre>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer>
        <div class="container">
            <div class="footer-content">
                <div class="footer-section">
                    <h3>Contact</h3>
                    <p>For questions about this work, please contact:</p>
                    <p><a href="mailto:nkp269@nyu.edu">nkp269@nyu.edu</a></p>
                </div>
            </div>

            <div class="footer-bottom">
                <p>&copy; 2025 NYU Tandon School of Engineering. All rights reserved.</p>
            </div>
        </div>
    </footer>

    <!-- Scripts -->
    <script src="js/main.js"></script>
</body>

</html>